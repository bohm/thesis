\section{Parallelization}\label{subsec:para}

Up until now, we have described a single-threaded minimax algorithm
with caching and pruning. We have used this single-threaded version in
\cite{bohm16} to improve on the results of Gabay, Brauner and Kotov
\cite{gabay2013lbv2} and reach a lower bound of $45/33 =
1.\overline{36}$ for $3$ bins and a lower bound of $19/14$ for up to
$5$ bins.

In the pursuit of an improved bound for $3$ bins as well as a general
lower bound for $m$ bins, we have subsequently implemented a parallel
version of the minimax search algorithm.

\paragraph{Tasks.} Our evaluation of the game tree proceeds in the
following way: First, we start evaluating the game tree on the main
computer (which we internally call \emph{queen}) until a vertex
corresponding to \adversary's next move meets a certain threshold (for
instance, sufficient depth). After that, we designate this adversarial
vertex as a \emph{task}.

Alongside the queen, we have processes whose job is to evaluate the
tasks -- we call them the \emph{workers}. Workers which run on the
same machine will have a common cache that they access via atomic
primitives in order to maintain consistency. Workers on separate
machines do not share information.

Due to the mixed environment of standard Unix threads and MPI
processes, we also have a single \emph{overseer} per each physical
machine. This overseer handles the MPI communication as well as
spawning the individual worker threads.

The tasks are all generated in advance by the queen. After that, their
bin configurations are synchronized with all overseers running. The
queen then assign tasks to overseers online, namely by assigning a
batch of 250-500 tasks to an overseer. The overseer reports each value
of a finished task immediately to the queen. When an overseer is
finished processing a batch, it requests and receives a new one.

We have selected this communication strategy for two reasons:

\begin{enumerate}
\item To minimize congestion in the processing phase through the fact
that the bin configurations are synchronized beforehand and only
identifiers are shared in the online assignment phase.
\item To allow the queen to evaluate and prune unfinished tasks and
therefore avoid some unnecessary processing by the workers.
\end{enumerate}

\paragraph{Task selection.} As mentioned above, an important decision
to be made by the lower bound algorithm designer is where to split a
vertex of the game tree into a task and send it to be processed in the
parallel environment.

Based on our experiments, it seems that maintaining a right balance of
the number of tasks as well as their running time is crucial to good
performance. When the tasks are too shallow, the performance of the
algorithm is dominated by the elapsed time of the most difficult task
in the list, which diminishes the gains coming from the parallel
implementation.

On the other hand, if there are millions of tasks, the algorithms will
still work correctly but we might lose performance from diminishing
advantages of individual caching as well as due to pruning happening
later in the process.

Previously, we have only used \emph{task depth} as the principal
guideline -- when $k$ items arrived on input (with $k$ usually in the
range of $\{4,5,6\}$), we mark the bin configuration as a new task.

However, experimenting with running time has shown us that the
presence of a larger item makes the evaluation process faster a lot
more than we assumed it will. Therefore, we have ultimately settled an
a mixed task threshold function which takes into account both the task
depth $k$ and also the \emph{task load} $l$, which is the sum of sizes
of all items arrived so far in the instance. We split off a task when
its task load is above $l$, and failing that when its task depth is
below $k$.

We have settled on setting $k \in \{5,6,7\}$ and $l$ to be around
$20-40\%$ of the optimal bin capacity $T$. This way we get deeper bin
configurations for very small items which experimentally seems to
imply a shorter running time and a similar amount of tasks.

\paragraph{Saplings.} Our implementation also allows us to pre-select
some initial strategy for the player \adversary in advance. This way
we can use our (so far limited) intuitive understanding of what is a
good initial move and decrease the time needed to evalate the whole
tree.

A particularly good strategy for the lower bound of $19/14$ seems to
be sending an item of size $5$ as the first item, followed by $m-1$
items of size $1$. This adversarial strategy leads to a lower bound
instance for $6,7,8$ and $9$ bins.

We have therefore implemented a way to pre-select items to be sent in
the first few rounds of the game. Given such a list of items, we
compute all possible moves of the player \algo and create a queue of
bin configurations that we each evaluate sequentially. We call such
configurations \emph{saplings}, as they are used to grow a full game
tree.

The fact that already this linear, non-adaptive strategy of sending
$5,1,1,1,\ldots$ is enough to get a lower bound of $19/14$ for $9$
bins was a pleasant surprise to us. We believe this fact is due to the
size of the sequence being already non-trivial (the item $5$ alone
occupies slightly more than $25\%$ of one stretched bin).

A natural extension is to allow the user to input a partial game tree
(an adaptive strategy for the player \adversary) and have the
algorithm evaluate it sequentially; this can be easily added to our
implementation once we learn more about which items should be the
among the first to send.

\paragraph{Generating the game tree.} So far we have only described
how to learn whether a game tree is winning for the player \adversary
(and thus is a valid lower bound) or winning for \algo. Naturally, our
program does more than that: When a lower bound is found, it generates
the game tree corresponding to the right choices of the player
\adversary.

To facilitate this, our main evaluation process (the queen) creates a
vertex representing all states in the top of the tree which it has in
memory. Unlike the worker processes, the queen does not use caching,
and so the top of the tree is represented in its entirety.

As the tasks are evaluated by the workers, the queen receives
information about winning and losing tasks, it prunes the top of the
tree and removes the moves which are winning for \algo, meaning that
at the end of the evaluation, only a small part of the original tree
top remains -- the one directly corresponding to a winning strategy
for the player \adversary.

After the evaluation is finished, we mark all the remaining vertices
in the top of the tree as \emph{fixed}, meaning we will not remove
them or edit them anymore. We increase the values of $k$ and $l$ (the
task load and the task depth above) and call the generating process
again on the root of the tree.

When the generating process reaches a fixed vertex with outdegree
non-zero, it will just move along the created out-edges and will not
create a new ones.

Once it reaches a vertex with oudegree zero (a task in the previous
iteration) it will again start generating all possible items allowed
to be sent by the player \adversary, up until the new task thresholds
are reached. We send these tasks are sent to the worker processes
again and we repeat our trimming and fixing process above.

\paragraph{Technology.} We have settled on using a combination of
OpenMPI \cite{openmpi} and standard thread library as provided by the
C++ programming language. In our setting, OpenMPI is used to provide
inter-computer communication API for sending and receiving tasks as
described above. We employ the standard Unix threads to spawn the
worker processes themselves; this way they can easily share one large
cache for evaluated bin configurations.

We have originally considered using only OpenMPI processes for both
inter-computer communication as well as memory sharing on one physical
computer; this functionality is present in the latest version of the
MPI standard, MPI-3.0. However, after implementing the shared memory
functionality, we have noticed some slowdown of the worker processes
when the shared memory was large (more than 1 gigabyte). This forced
us into the heterogenous model that we use right now.

